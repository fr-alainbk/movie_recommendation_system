{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building A Movie Recommandation System With Pytorch\n",
    "\n",
    "In this project, we are trying to predict the ratings that a user will give to an unseen movie, based on the ratings he gave to other movies. We will use the [movielens dataset](https://grouplens.org/datasets/movielens/). Two main folders contain our data. One folder named *ml-1m* which contains informations about 1 million movies. The other folder, which is *ml-100k* contains informations about 100 000 movies. We will use AutoEncoders to create our recommandation system. Let's start by importing the required libraries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AutoEncoders\n",
    "\n",
    "# Importing the libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.parallel\n",
    "import torch.optim as optim\n",
    "import torch.utils.data\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's consider the folder *ml-1m*. In this folder, we've got the files:\n",
    "- movies.dat : contains informations related to a movie (movie_id, movie_title, movie_genre)\n",
    "- users.dat : contains informations related to a user\n",
    "- ratings.dat : contains the ratings given by users on different movies\n",
    "\n",
    "We can import these files using pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the dataset\n",
    "movies = pd.read_csv('C:/Users/user/.spyder-py3/P16-AutoEncoders/AutoEncoders/ml-1m/ml-1m/movies.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "users = pd.read_csv('C:/Users/user/.spyder-py3/P16-AutoEncoders/AutoEncoders/ml-1m/ml-1m/users.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n",
    "ratings = pd.read_csv('C:/Users/user/.spyder-py3/P16-AutoEncoders/AutoEncoders/ml-1m/ml-1m/ratings.dat', sep = '::', header = None, engine = 'python', encoding = 'latin-1')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Animation|Children's|Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children's|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                   1                             2\n",
       "0  1                    Toy Story (1995)   Animation|Children's|Comedy\n",
       "1  2                      Jumanji (1995)  Adventure|Children's|Fantasy\n",
       "2  3             Grumpier Old Men (1995)                Comedy|Romance\n",
       "3  4            Waiting to Exhale (1995)                  Comedy|Drama\n",
       "4  5  Father of the Bride Part II (1995)                        Comedy"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the first elements of the movies dataset\n",
    "movies.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *movies* dataset contains three columns:\n",
    "- column 0: contains the movie_id\n",
    "- column 1: contains the title of the movie\n",
    "- column 2: contains the genre of the movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>48067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>M</td>\n",
       "      <td>56</td>\n",
       "      <td>16</td>\n",
       "      <td>70072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>15</td>\n",
       "      <td>55117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>M</td>\n",
       "      <td>45</td>\n",
       "      <td>7</td>\n",
       "      <td>02460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>M</td>\n",
       "      <td>25</td>\n",
       "      <td>20</td>\n",
       "      <td>55455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0  1   2   3      4\n",
       "0  1  F   1  10  48067\n",
       "1  2  M  56  16  70072\n",
       "2  3  M  25  15  55117\n",
       "3  4  M  45   7  02460\n",
       "4  5  M  25  20  55455"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the first elements of the users dataset\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1193</td>\n",
       "      <td>5</td>\n",
       "      <td>978300760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>661</td>\n",
       "      <td>3</td>\n",
       "      <td>978302109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>914</td>\n",
       "      <td>3</td>\n",
       "      <td>978301968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3408</td>\n",
       "      <td>4</td>\n",
       "      <td>978300275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2355</td>\n",
       "      <td>5</td>\n",
       "      <td>978824291</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0     1  2          3\n",
       "0  1  1193  5  978300760\n",
       "1  1   661  3  978302109\n",
       "2  1   914  3  978301968\n",
       "3  1  3408  4  978300275\n",
       "4  1  2355  5  978824291"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the first elements of the ratings dataset\n",
    "ratings.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *ratings* dataset has four columns:\n",
    "- column 0 : contains the user_id x\n",
    "- column 1: contains the movie_id y\n",
    "- columns 2: contains the rating that a user x  gave to the movie y\n",
    "- column 3: contains the timestamp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will train the autoencoder using a subset of the data. The folder *ml-100k* contains a file named *u1.base*, which is the file we'll use to train the model. This subset itslef contains the ratings of users. We will then test our algorithm using the *u1.test* file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the training set and the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing the training set and the test set\n",
    "\n",
    "training_set = pd.read_csv('C:/Users/user/.spyder-py3/P16-AutoEncoders/AutoEncoders/ml-100k/ml-100k/u1.base', delimiter = '\\t')\n",
    "test_set = pd.read_csv('C:/Users/user/.spyder-py3/P16-AutoEncoders/AutoEncoders/ml-100k/ml-100k/u1.test', delimiter = '\\t')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>1.1</th>\n",
       "      <th>5</th>\n",
       "      <th>874965758</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>876893171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>876893119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>889751712</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>875071561</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1  1.1  5  874965758\n",
       "0  1    2  3  876893171\n",
       "1  1    3  4  878542960\n",
       "2  1    4  3  876893119\n",
       "3  1    5  3  889751712\n",
       "4  1    7  4  875071561"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the first elements of the training_set\n",
    "training_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first three columns of the training_set represent the user_id, the movie_id, and the rating respectively. The same thing is applicable for the test_set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>6</th>\n",
       "      <th>5</th>\n",
       "      <th>887431973</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>875693118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "      <td>878542960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "      <td>874965706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>875073198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>887431883</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   1   6  5  887431973\n",
       "0  1  10  3  875693118\n",
       "1  1  12  5  878542960\n",
       "2  1  14  5  874965706\n",
       "3  1  17  3  875073198\n",
       "4  1  20  4  887431883"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Visualizing the first elements of the test_set\n",
    "test_set.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use Pytorch to create the Autoencoder. Pytorch expects numpy arrays in order to deal with the data without throwing an error. Therefore, we have to convert our dataframe into numpy arrays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the training and test sets into numpy arrays\n",
    "training_set = np.array(training_set, dtype = 'int')\n",
    "test_set = np.array(test_set, dtype = 'int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll need the number of users and the number of movies to build our recommendation system. Since id_users and id_movies start at index 1, the number of users represent the maximum value of id_user. Similarly, the number of movies represent the maximum value of id_movie. However, since the data is divided into training and test set, the maximum value of id_user/id_movie is either in the training_set or in the test_set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the number of users and movies\n",
    "nb_users = int(max(max(training_set[:, 0]), max(test_set[:, 0])))\n",
    "nb_movies = int(max(max(training_set[:, 1]), max(test_set[:, 1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of users: 943\n",
      "Number of movies: 1682\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of users: {}\".format(nb_users))\n",
    "print(\"Number of movies: {}\".format(nb_movies))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build the autoencoder, we need a specific data structure. In our case, we will create a list of lists, expected by Pytorch. Each list of list will contain the ratings that a specific user gave to the movies. If a user didn't rate a movie, we'll just add a 0 for that observation. We will define a function which will create this list of list for us. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting the data into an array with users in lines and movies in columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert(data):\n",
    "    # Initializing an empty list that will take the list of ratings given by a specific user\n",
    "    new_data = []\n",
    "    # Looping over all the users\n",
    "    for id_users in range(1, nb_users + 1):\n",
    "        # We get the id of the movies rated by the current user\n",
    "        id_movies = data[:, 1][data[:, 0] == id_users]\n",
    "        # We get the id of the ratings given by the current_user\n",
    "        id_ratings = data[:, 2][data[:, 0] == id_users]\n",
    "        # \n",
    "        ratings = np.zeros(nb_movies)\n",
    "        # For movies rated by the current user, we replace 0 with the rating\n",
    "        # The first element of ratings is at index 0. However, id_movies start at index 1.\n",
    "        # Therefore, ratings[id_movies - 1] will correspond to the location of the movie we're considering\n",
    "        ratings[id_movies - 1] = id_ratings\n",
    "        new_data.append(list(ratings))\n",
    "    return new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the convert function to the training and test set.\n",
    "training_set = convert(training_set)\n",
    "test_set = convert(test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data into Torch tensors\n",
    "training_set = torch.FloatTensor(training_set)\n",
    "test_set = torch.FloatTensor(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the architecture of the Neural Network\n",
    "\n",
    "We'll create a stacked autoencoder. This stacked autoencoder will get one input layer, two encoding layers and two decoding layers. As a reminder, for an autoencoder, the number of nodes of the output layer should equal the number of nodes of the input layer. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![autoencoder](https://miro.medium.com/max/3524/1*oUbsOnYKX5DEpMOK3pH_lg.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will create the SAE (stack autoencoder) class, which is inherited from nn.Module\n",
    "class SAE(nn.Module):\n",
    "    # Initializing the class\n",
    "    def __init__(self, ):\n",
    "        # making the class get all the functions from the parent class nn.Module\n",
    "        super(SAE, self).__init__()\n",
    "        # Creating the first encoding layer. The number of input corresponds to the number of movies\n",
    "        # We decide to encode it into 20 outputs\n",
    "        self.fc1 = nn.Linear(nb_movies, 20)\n",
    "        # Creating the second encoding layer. From 20 inputs to 10 outputs\n",
    "        self.fc2 = nn.Linear(20, 10)\n",
    "        # Creating the first decoding layer. From 10 inputs to 20 outputs\n",
    "        self.fc3 = nn.Linear(10, 20)\n",
    "        # Creating the second hidden layer. From 20 inputs to nb_movies outputs\n",
    "        self.fc4 = nn.Linear(20, nb_movies)\n",
    "        # Creating the activation fucntion which will fire up specific neurons \n",
    "        self.activation = nn.Sigmoid()\n",
    "        \n",
    "        # Creating the function for forward propagation\n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        # With autoencoder, we don't need an activation function for the last decoding part\n",
    "        x = self.fc4(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating an instance of our SAE class\n",
    "sae = SAE()\n",
    "# Defining a criterion which specifies the metric to minimize. In this case, we want to minimize the MSE (Mean Squared Error)\n",
    "criterion = nn.MSELoss()\n",
    "# Defining the algorithm used to minimize the loss function. In this case, we'll use RMSprop\n",
    "optimizer = optim.RMSprop(sae.parameters(), lr = 0.01, weight_decay = 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1 loss: tensor(1.7715)\n",
      "epoch: 2 loss: tensor(1.0964)\n",
      "epoch: 3 loss: tensor(1.0533)\n",
      "epoch: 4 loss: tensor(1.0383)\n",
      "epoch: 5 loss: tensor(1.0308)\n",
      "epoch: 6 loss: tensor(1.0268)\n",
      "epoch: 7 loss: tensor(1.0239)\n",
      "epoch: 8 loss: tensor(1.0218)\n",
      "epoch: 9 loss: tensor(1.0208)\n",
      "epoch: 10 loss: tensor(1.0198)\n",
      "epoch: 11 loss: tensor(1.0188)\n",
      "epoch: 12 loss: tensor(1.0186)\n",
      "epoch: 13 loss: tensor(1.0180)\n",
      "epoch: 14 loss: tensor(1.0175)\n",
      "epoch: 15 loss: tensor(1.0173)\n",
      "epoch: 16 loss: tensor(1.0170)\n",
      "epoch: 17 loss: tensor(1.0167)\n",
      "epoch: 18 loss: tensor(1.0165)\n",
      "epoch: 19 loss: tensor(1.0164)\n",
      "epoch: 20 loss: tensor(1.0162)\n",
      "epoch: 21 loss: tensor(1.0161)\n",
      "epoch: 22 loss: tensor(1.0161)\n",
      "epoch: 23 loss: tensor(1.0158)\n",
      "epoch: 24 loss: tensor(1.0157)\n",
      "epoch: 25 loss: tensor(1.0156)\n",
      "epoch: 26 loss: tensor(1.0156)\n",
      "epoch: 27 loss: tensor(1.0153)\n",
      "epoch: 28 loss: tensor(1.0150)\n",
      "epoch: 29 loss: tensor(1.0128)\n",
      "epoch: 30 loss: tensor(1.0113)\n",
      "epoch: 31 loss: tensor(1.0101)\n",
      "epoch: 32 loss: tensor(1.0077)\n",
      "epoch: 33 loss: tensor(1.0072)\n",
      "epoch: 34 loss: tensor(1.0037)\n",
      "epoch: 35 loss: tensor(1.0024)\n",
      "epoch: 36 loss: tensor(0.9994)\n",
      "epoch: 37 loss: tensor(0.9981)\n",
      "epoch: 38 loss: tensor(0.9963)\n",
      "epoch: 39 loss: tensor(0.9957)\n",
      "epoch: 40 loss: tensor(0.9918)\n",
      "epoch: 41 loss: tensor(0.9895)\n",
      "epoch: 42 loss: tensor(0.9877)\n",
      "epoch: 43 loss: tensor(0.9888)\n",
      "epoch: 44 loss: tensor(0.9870)\n",
      "epoch: 45 loss: tensor(0.9865)\n",
      "epoch: 46 loss: tensor(0.9834)\n",
      "epoch: 47 loss: tensor(0.9824)\n",
      "epoch: 48 loss: tensor(0.9809)\n",
      "epoch: 49 loss: tensor(0.9805)\n",
      "epoch: 50 loss: tensor(0.9798)\n",
      "epoch: 51 loss: tensor(0.9827)\n",
      "epoch: 52 loss: tensor(0.9763)\n",
      "epoch: 53 loss: tensor(0.9770)\n",
      "epoch: 54 loss: tensor(0.9725)\n",
      "epoch: 55 loss: tensor(0.9751)\n",
      "epoch: 56 loss: tensor(0.9705)\n",
      "epoch: 57 loss: tensor(0.9705)\n",
      "epoch: 58 loss: tensor(0.9669)\n",
      "epoch: 59 loss: tensor(0.9648)\n",
      "epoch: 60 loss: tensor(0.9611)\n",
      "epoch: 61 loss: tensor(0.9592)\n",
      "epoch: 62 loss: tensor(0.9581)\n",
      "epoch: 63 loss: tensor(0.9595)\n",
      "epoch: 64 loss: tensor(0.9561)\n",
      "epoch: 65 loss: tensor(0.9582)\n",
      "epoch: 66 loss: tensor(0.9546)\n",
      "epoch: 67 loss: tensor(0.9550)\n",
      "epoch: 68 loss: tensor(0.9547)\n",
      "epoch: 69 loss: tensor(0.9514)\n",
      "epoch: 70 loss: tensor(0.9495)\n",
      "epoch: 71 loss: tensor(0.9494)\n",
      "epoch: 72 loss: tensor(0.9463)\n",
      "epoch: 73 loss: tensor(0.9470)\n",
      "epoch: 74 loss: tensor(0.9458)\n",
      "epoch: 75 loss: tensor(0.9465)\n",
      "epoch: 76 loss: tensor(0.9439)\n",
      "epoch: 77 loss: tensor(0.9457)\n",
      "epoch: 78 loss: tensor(0.9419)\n",
      "epoch: 79 loss: tensor(0.9420)\n",
      "epoch: 80 loss: tensor(0.9404)\n",
      "epoch: 81 loss: tensor(0.9411)\n",
      "epoch: 82 loss: tensor(0.9384)\n",
      "epoch: 83 loss: tensor(0.9405)\n",
      "epoch: 84 loss: tensor(0.9370)\n",
      "epoch: 85 loss: tensor(0.9395)\n",
      "epoch: 86 loss: tensor(0.9363)\n",
      "epoch: 87 loss: tensor(0.9388)\n",
      "epoch: 88 loss: tensor(0.9351)\n",
      "epoch: 89 loss: tensor(0.9377)\n",
      "epoch: 90 loss: tensor(0.9344)\n",
      "epoch: 91 loss: tensor(0.9364)\n",
      "epoch: 92 loss: tensor(0.9337)\n",
      "epoch: 93 loss: tensor(0.9345)\n",
      "epoch: 94 loss: tensor(0.9330)\n",
      "epoch: 95 loss: tensor(0.9347)\n",
      "epoch: 96 loss: tensor(0.9326)\n",
      "epoch: 97 loss: tensor(0.9342)\n",
      "epoch: 98 loss: tensor(0.9318)\n",
      "epoch: 99 loss: tensor(0.9331)\n",
      "epoch: 100 loss: tensor(0.9322)\n",
      "epoch: 101 loss: tensor(0.9331)\n",
      "epoch: 102 loss: tensor(0.9313)\n",
      "epoch: 103 loss: tensor(0.9321)\n",
      "epoch: 104 loss: tensor(0.9300)\n",
      "epoch: 105 loss: tensor(0.9317)\n",
      "epoch: 106 loss: tensor(0.9301)\n",
      "epoch: 107 loss: tensor(0.9313)\n",
      "epoch: 108 loss: tensor(0.9300)\n",
      "epoch: 109 loss: tensor(0.9307)\n",
      "epoch: 110 loss: tensor(0.9294)\n",
      "epoch: 111 loss: tensor(0.9303)\n",
      "epoch: 112 loss: tensor(0.9289)\n",
      "epoch: 113 loss: tensor(0.9302)\n",
      "epoch: 114 loss: tensor(0.9284)\n",
      "epoch: 115 loss: tensor(0.9292)\n",
      "epoch: 116 loss: tensor(0.9272)\n",
      "epoch: 117 loss: tensor(0.9280)\n",
      "epoch: 118 loss: tensor(0.9275)\n",
      "epoch: 119 loss: tensor(0.9277)\n",
      "epoch: 120 loss: tensor(0.9262)\n",
      "epoch: 121 loss: tensor(0.9272)\n",
      "epoch: 122 loss: tensor(0.9265)\n",
      "epoch: 123 loss: tensor(0.9270)\n",
      "epoch: 124 loss: tensor(0.9258)\n",
      "epoch: 125 loss: tensor(0.9274)\n",
      "epoch: 126 loss: tensor(0.9255)\n",
      "epoch: 127 loss: tensor(0.9264)\n",
      "epoch: 128 loss: tensor(0.9251)\n",
      "epoch: 129 loss: tensor(0.9259)\n",
      "epoch: 130 loss: tensor(0.9241)\n",
      "epoch: 131 loss: tensor(0.9253)\n",
      "epoch: 132 loss: tensor(0.9239)\n",
      "epoch: 133 loss: tensor(0.9248)\n",
      "epoch: 134 loss: tensor(0.9237)\n",
      "epoch: 135 loss: tensor(0.9245)\n",
      "epoch: 136 loss: tensor(0.9225)\n",
      "epoch: 137 loss: tensor(0.9236)\n",
      "epoch: 138 loss: tensor(0.9225)\n",
      "epoch: 139 loss: tensor(0.9231)\n",
      "epoch: 140 loss: tensor(0.9217)\n",
      "epoch: 141 loss: tensor(0.9229)\n",
      "epoch: 142 loss: tensor(0.9219)\n",
      "epoch: 143 loss: tensor(0.9228)\n",
      "epoch: 144 loss: tensor(0.9218)\n",
      "epoch: 145 loss: tensor(0.9223)\n",
      "epoch: 146 loss: tensor(0.9208)\n",
      "epoch: 147 loss: tensor(0.9217)\n",
      "epoch: 148 loss: tensor(0.9196)\n",
      "epoch: 149 loss: tensor(0.9206)\n",
      "epoch: 150 loss: tensor(0.9193)\n",
      "epoch: 151 loss: tensor(0.9209)\n",
      "epoch: 152 loss: tensor(0.9199)\n",
      "epoch: 153 loss: tensor(0.9208)\n",
      "epoch: 154 loss: tensor(0.9188)\n",
      "epoch: 155 loss: tensor(0.9205)\n",
      "epoch: 156 loss: tensor(0.9184)\n",
      "epoch: 157 loss: tensor(0.9196)\n",
      "epoch: 158 loss: tensor(0.9178)\n",
      "epoch: 159 loss: tensor(0.9183)\n",
      "epoch: 160 loss: tensor(0.9172)\n",
      "epoch: 161 loss: tensor(0.9183)\n",
      "epoch: 162 loss: tensor(0.9174)\n",
      "epoch: 163 loss: tensor(0.9184)\n",
      "epoch: 164 loss: tensor(0.9173)\n",
      "epoch: 165 loss: tensor(0.9186)\n",
      "epoch: 166 loss: tensor(0.9172)\n",
      "epoch: 167 loss: tensor(0.9180)\n",
      "epoch: 168 loss: tensor(0.9164)\n",
      "epoch: 169 loss: tensor(0.9174)\n",
      "epoch: 170 loss: tensor(0.9159)\n",
      "epoch: 171 loss: tensor(0.9164)\n",
      "epoch: 172 loss: tensor(0.9158)\n",
      "epoch: 173 loss: tensor(0.9168)\n",
      "epoch: 174 loss: tensor(0.9162)\n",
      "epoch: 175 loss: tensor(0.9165)\n",
      "epoch: 176 loss: tensor(0.9149)\n",
      "epoch: 177 loss: tensor(0.9161)\n",
      "epoch: 178 loss: tensor(0.9151)\n",
      "epoch: 179 loss: tensor(0.9164)\n",
      "epoch: 180 loss: tensor(0.9157)\n",
      "epoch: 181 loss: tensor(0.9156)\n",
      "epoch: 182 loss: tensor(0.9145)\n",
      "epoch: 183 loss: tensor(0.9155)\n",
      "epoch: 184 loss: tensor(0.9139)\n",
      "epoch: 185 loss: tensor(0.9152)\n",
      "epoch: 186 loss: tensor(0.9142)\n",
      "epoch: 187 loss: tensor(0.9153)\n",
      "epoch: 188 loss: tensor(0.9146)\n",
      "epoch: 189 loss: tensor(0.9150)\n",
      "epoch: 190 loss: tensor(0.9132)\n",
      "epoch: 191 loss: tensor(0.9150)\n",
      "epoch: 192 loss: tensor(0.9133)\n",
      "epoch: 193 loss: tensor(0.9150)\n",
      "epoch: 194 loss: tensor(0.9136)\n",
      "epoch: 195 loss: tensor(0.9142)\n",
      "epoch: 196 loss: tensor(0.9127)\n",
      "epoch: 197 loss: tensor(0.9143)\n",
      "epoch: 198 loss: tensor(0.9134)\n",
      "epoch: 199 loss: tensor(0.9138)\n",
      "epoch: 200 loss: tensor(0.9124)\n"
     ]
    }
   ],
   "source": [
    "# Setting the number of epochs\n",
    "nb_epoch = 200\n",
    "# Iterating over each epoch\n",
    "for epoch in range(1, nb_epoch + 1):\n",
    "    # Initializing the train_loss which will be updated\n",
    "    train_loss = 0\n",
    "    # Initializing a counter\n",
    "    s = 0.\n",
    "    # Iterating over each user\n",
    "    for id_user in range(nb_users):\n",
    "        # The input corresponds to the ratings given by the current user for each movie\n",
    "        input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "        target = input.clone()\n",
    "        # We don't consider movies NOT rated by the current user. So we specify a conditional statement\n",
    "        if torch.sum(target.data > 0) > 0:\n",
    "            # We use our SAE to get the output from the \n",
    "            output = sae(input)\n",
    "            target.require_grad = False\n",
    "            output[target == 0] = 0\n",
    "            # Defining our loss function, comparing the output with the target\n",
    "            loss = criterion(output, target)\n",
    "            mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "            # Computing the gradients necessary to adjust the weights\n",
    "            loss.backward()\n",
    "            # Updating the train_loss\n",
    "            train_loss += np.sqrt(loss.data*mean_corrector)\n",
    "            s += 1.\n",
    "            # Updating the weights of the neural network\n",
    "            optimizer.step()\n",
    "    print('epoch: '+str(epoch)+' loss: '+str(train_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After a training of 200 epochs, we get an overall lost of 0.9124. This means that for the training_set, we have : **predicted_rating - 0.9124 <= real_rating <= predicted_rating + 0.9124**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test_loss: tensor(0.9517)\n"
     ]
    }
   ],
   "source": [
    "# Initializing the test_loss\n",
    "test_loss = 0\n",
    "s = 0.\n",
    "for id_user in range(nb_users):\n",
    "    input = Variable(training_set[id_user]).unsqueeze(0)\n",
    "    target = Variable(test_set[id_user]).unsqueeze(0)\n",
    "    if torch.sum(target.data > 0) > 0:\n",
    "        output = sae(input)\n",
    "        target.require_grad = False\n",
    "        output[(target == 0)] = 0\n",
    "        loss = criterion(output, target)\n",
    "        mean_corrector = nb_movies/float(torch.sum(target.data > 0) + 1e-10)\n",
    "        test_loss += np.sqrt(loss.data*mean_corrector)\n",
    "        s += 1.\n",
    "print('test_loss: '+str(test_loss/s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The test_loss is 0.9517. Therefore, for this specific test_set, we have : **predicted_rating - 0.9517 <= real_rating <= predicted_rating + 0.9517**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
